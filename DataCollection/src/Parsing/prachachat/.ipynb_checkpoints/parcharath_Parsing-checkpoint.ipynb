{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdf6de1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing article 13: module 'datetime' has no attribute 'strptime'\n",
      "Error processing article 20: module 'datetime' has no attribute 'strptime'\n",
      "Error processing article 21: module 'datetime' has no attribute 'strptime'\n",
      "Error processing article 22: module 'datetime' has no attribute 'strptime'\n",
      "Error processing article 25: module 'datetime' has no attribute 'strptime'\n",
      "Error processing article 32: module 'datetime' has no attribute 'strptime'\n",
      "Error processing article 34: module 'datetime' has no attribute 'strptime'\n",
      "Error processing article 35: module 'datetime' has no attribute 'strptime'\n",
      "Error processing article 41: module 'datetime' has no attribute 'strptime'\n",
      "Error processing article 42: module 'datetime' has no attribute 'strptime'\n",
      "Error processing article 48: module 'datetime' has no attribute 'strptime'\n",
      "Error processing article 50: module 'datetime' has no attribute 'strptime'\n",
      "Error processing article 51: module 'datetime' has no attribute 'strptime'\n",
      "Error processing article 54: module 'datetime' has no attribute 'strptime'\n",
      "Error processing article 56: module 'datetime' has no attribute 'strptime'\n",
      "Error processing article 64: module 'datetime' has no attribute 'strptime'\n",
      "Error processing article 65: module 'datetime' has no attribute 'strptime'\n",
      "Error processing article 67: module 'datetime' has no attribute 'strptime'\n",
      "Error processing article 69: module 'datetime' has no attribute 'strptime'\n",
      "Error processing article 75: module 'datetime' has no attribute 'strptime'\n",
      "Error processing article 81: module 'datetime' has no attribute 'strptime'\n",
      "Error processing article 82: module 'datetime' has no attribute 'strptime'\n",
      "Error processing article 84: module 'datetime' has no attribute 'strptime'\n",
      "Error processing article 98: module 'datetime' has no attribute 'strptime'\n",
      "Error processing article 101: module 'datetime' has no attribute 'strptime'\n",
      "Error processing article 102: module 'datetime' has no attribute 'strptime'\n",
      "Error processing article 111: module 'datetime' has no attribute 'strptime'\n",
      "Error processing article 119: module 'datetime' has no attribute 'strptime'\n",
      "Error processing article 120: module 'datetime' has no attribute 'strptime'\n",
      "Error processing article 122: module 'datetime' has no attribute 'strptime'\n",
      "Error processing article 129: module 'datetime' has no attribute 'strptime'\n",
      "Error processing article 133: module 'datetime' has no attribute 'strptime'\n",
      "Error processing article 135: module 'datetime' has no attribute 'strptime'\n",
      "Error processing article 136: module 'datetime' has no attribute 'strptime'\n",
      "Error processing article 141: module 'datetime' has no attribute 'strptime'\n",
      "Error processing article 145: module 'datetime' has no attribute 'strptime'\n",
      "Error processing article 148: module 'datetime' has no attribute 'strptime'\n",
      "Error processing article 149: module 'datetime' has no attribute 'strptime'\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sp2023-stock\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3505, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\sp2023-stock\\AppData\\Local\\Temp\\ipykernel_8532\\731614023.py\", line 136, in <module>\n",
      "    soup = htmlInput(file_path)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sp2023-stock\\AppData\\Local\\Temp\\ipykernel_8532\\731614023.py\", line 16, in htmlInput\n",
      "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sp2023-stock\\anaconda3\\Lib\\site-packages\\bs4\\__init__.py\", line 335, in __init__\n",
      "    self._feed()\n",
      "  File \"C:\\Users\\sp2023-stock\\anaconda3\\Lib\\site-packages\\bs4\\__init__.py\", line 478, in _feed\n",
      "    self.builder.feed(self.markup)\n",
      "  File \"C:\\Users\\sp2023-stock\\anaconda3\\Lib\\site-packages\\bs4\\builder\\_htmlparser.py\", line 380, in feed\n",
      "    parser.feed(markup)\n",
      "  File \"C:\\Users\\sp2023-stock\\anaconda3\\Lib\\html\\parser.py\", line 110, in feed\n",
      "    self.goahead(0)\n",
      "  File \"C:\\Users\\sp2023-stock\\anaconda3\\Lib\\html\\parser.py\", line 170, in goahead\n",
      "    k = self.parse_starttag(i)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sp2023-stock\\anaconda3\\Lib\\html\\parser.py\", line 337, in parse_starttag\n",
      "    self.handle_starttag(tag, attrs)\n",
      "  File \"C:\\Users\\sp2023-stock\\anaconda3\\Lib\\site-packages\\bs4\\builder\\_htmlparser.py\", line 137, in handle_starttag\n",
      "    tag = self.soup.handle_starttag(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sp2023-stock\\anaconda3\\Lib\\site-packages\\bs4\\__init__.py\", line 749, in handle_starttag\n",
      "    tag = self.element_classes.get(Tag, Tag)(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sp2023-stock\\anaconda3\\Lib\\site-packages\\bs4\\element.py\", line 1262, in __init__\n",
      "    attrs = builder._replace_cdata_list_attribute_values(\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sp2023-stock\\anaconda3\\Lib\\site-packages\\bs4\\builder\\__init__.py\", line -1, in _replace_cdata_list_attribute_values\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sp2023-stock\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2102, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sp2023-stock\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1310, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sp2023-stock\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1199, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sp2023-stock\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1052, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sp2023-stock\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 978, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sp2023-stock\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 878, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sp2023-stock\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 712, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sp2023-stock\\anaconda3\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sp2023-stock\\anaconda3\\Lib\\site-packages\\stack_data\\core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sp2023-stock\\anaconda3\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sp2023-stock\\anaconda3\\Lib\\site-packages\\stack_data\\core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sp2023-stock\\anaconda3\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sp2023-stock\\anaconda3\\Lib\\site-packages\\stack_data\\core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"C:\\Users\\sp2023-stock\\anaconda3\\Lib\\site-packages\\executing\\executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "import chardet\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# Detect input file\n",
    "def htmlInput(file_path):\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        encoding_result = chardet.detect(file.read())\n",
    "    with open(file_path, \"r\", encoding=encoding_result[\"encoding\"]) as file:\n",
    "        html_content = file.read()\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "    return soup\n",
    "\n",
    "#Extract title\n",
    "def extract_title(soup):\n",
    "    title = soup.title.string.strip() if soup.title else None\n",
    "    return title\n",
    "\n",
    "#Extract body\n",
    "def extract_body(soup):\n",
    "    article_divs = soup.find_all(\"div\", itemprop = \"articleBody\")\n",
    "    articles = []\n",
    "    if article_divs:\n",
    "        \n",
    "        for inside_div in article_divs:\n",
    "            articleses = inside_div.find_all('p')\n",
    "            for article in articleses:\n",
    "                articles.append(article.get_text(strip=True))\n",
    "\n",
    "        articles = [s.replace('\\xa0', ' ') for s in articles]\n",
    "        articles = [item for item in articles if item != '']\n",
    "    else:\n",
    "        articles = None\n",
    "    \n",
    "    return articles\n",
    "\n",
    "#Extract tags\n",
    "def extract_tags(soup):\n",
    "    top_div = soup.find('div', class_='ud-post-category-title')\n",
    "    bott_div = soup.find('div', class_='td-post-source-tags')\n",
    "\n",
    "    top_tag = top_div.get_text(strip=True)\n",
    "\n",
    "    bott_tag = []\n",
    "\n",
    "    if bott_div:\n",
    "        tag_links = bott_div.find_all('a')\n",
    "        for tag_link in tag_links:\n",
    "            bott_tag.append(tag_link.get_text(strip=True))\n",
    "\n",
    "    if bott_tag and top_tag:\n",
    "        tag_content = bott_tag + [top_tag]\n",
    "    elif not bott_tag :\n",
    "        tag_content = top_tag\n",
    "\n",
    "    return tag_content\n",
    "\n",
    "#Extract date\n",
    "def extract_pubdate(soup):\n",
    "    date_time = soup.find('time', {'class': 'entry-date'}).get('datetime')\n",
    "    if date_time is not None:\n",
    "        date_object = datetime.strptime(date_time, \"%Y-%m-%dT%H:%M:%S%z\")\n",
    "        pubdate = date_object.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "         \n",
    "    else:\n",
    "        pubdate = None\n",
    "    \n",
    "    return pubdate\n",
    "\n",
    "\n",
    "#Extract title\n",
    "def extract_intro(soup):\n",
    "    intro_divs = soup.find_all(\"div\", itemprop=\"articleBody\")\n",
    "\n",
    "    intro = None  # Default value if nothing is found\n",
    "    for intro_div in intro_divs:\n",
    "        intro_paragraphs = intro_div.find_all('p')\n",
    "        for intro_paragraph in intro_paragraphs:\n",
    "            intro_strong = intro_paragraph.find('strong')\n",
    "            if intro_strong:\n",
    "                intro = intro_strong.get_text(strip=True)\n",
    "                break  # Exit the loop if we found what we were looking for\n",
    "    \n",
    "        if intro is None:\n",
    "            intro = intro_paragraphs[0].get_text(strip=True)\n",
    "            break  # Exit the outer loop if we found what we were looking for\n",
    "\n",
    "    return intro\n",
    "\n",
    "def extract_urlPic(soup):\n",
    "    img_div = soup.find(\"div\", class_=\"td-post-featured-image\")\n",
    "\n",
    "    if img_div is not None:\n",
    "        img_tag = img_div.find(\"img\", class_=\"entry-thumb\")\n",
    "\n",
    "        if img_tag is not None:\n",
    "            image_link = img_tag.get(\"data-cfsrc\")\n",
    "        else:\n",
    "            image_link = None\n",
    "    else:\n",
    "        image_link = None\n",
    "\n",
    "    return image_link\n",
    "\n",
    "\n",
    "#start using \"csv_progress\" (current progress of parsing)\n",
    "if os.path.exists('parsing_progress.txt'):\n",
    "    with open('parsing_progress.txt','r') as f:\n",
    "        progress_start = int(f.readline().strip())\n",
    "        start_id = progress_start - 1\n",
    "else: \n",
    "    start_id = 1 \n",
    "    \n",
    "article_id = start_id\n",
    "\n",
    "\n",
    "process = 'E:/Crimson_News/src/CrawlingCode/prachachat/progress.txt'\n",
    "\n",
    "#start using \"progress\" (last progress of crwaling)\n",
    "if os.path.exists(process):\n",
    "    with open(process,'r') as f:\n",
    "        progress_end = int(f.readline().strip())\n",
    "        end_id = progress_end + 1\n",
    "\n",
    "for article_id in range(start_id, end_id+1):\n",
    "    file_path = \"E:/Crimson_News/DataSet/prachachat/article/\" + str(article_id) + \"/index.txt\"\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        try:\n",
    "        \n",
    "            soup = htmlInput(file_path)\n",
    "            title = extract_title(soup)\n",
    "            intro = extract_intro(soup)\n",
    "            articles = extract_body(soup)\n",
    "            pubdate = extract_pubdate(soup)\n",
    "            tag_content = extract_tags(soup)\n",
    "            url = extract_urlPic(soup)\n",
    "\n",
    "            if title == intro:\n",
    "                intro = None\n",
    "            if articles and intro == articles[0]:\n",
    "                articles.pop(0)\n",
    "            if title == articles[0]:\n",
    "                articles.pop(0)\n",
    "\n",
    "\n",
    "            data_dict = {'Title': title, 'Intro': intro, 'Article': articles, 'DateTime': pubdate, 'Tags': tag_content, 'url_picture': url}\n",
    "\n",
    "            with open(os.path.join(\"E:/Crimson_News/DataSet/prachachat/article/\" + str(article_id) +\"/parsing.txt\"), 'w', encoding=\"utf-8\") as f:\n",
    "                for key, value in data_dict.items():\n",
    "                    if value is not None:\n",
    "                        if key == 'Tags' and isinstance(value, list):\n",
    "                            f.write(f\"[::{key}::]\\n\")\n",
    "                            for tags in value:\n",
    "                                f.write(f\"{tags}\\n\")\n",
    "\n",
    "                        elif key == 'Article' and isinstance(value, list):\n",
    "                            f.write(f\"[::{key}::]\\n\")\n",
    "                            for bodys in value:\n",
    "                                if bodys == 'SPONSORED':\n",
    "                                    continue\n",
    "                                else:\n",
    "                                    f.write(f\"{bodys}\\n\")\n",
    "                                    f.write(\"\\n\")\n",
    "                        else:\n",
    "                            f.write(f\"[::{key}::]\\n{value}\\n\")\n",
    "\n",
    "\n",
    "            with open('parsing_progress.txt', 'w') as f:\n",
    "                f.write(f'{article_id}')\n",
    "\n",
    "            with open('parsing_number.csv', 'a', newline='') as f:\n",
    "                writer = csv.writer(f)\n",
    "                validation = 'Valid'\n",
    "                writer.writerow([article_id, validation])\n",
    "\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing article {article_id}: {e}\")\n",
    "            with open('parsing_number.csv', 'a', newline='') as f:\n",
    "                writer = csv.writer(f)\n",
    "                validation = 'Error'\n",
    "                writer.writerow([article_id, validation])\n",
    "                continue\n",
    "\n",
    "\n",
    "# Write the last processed article_id to 'csv_progress.txt' after loop ends\n",
    "with open('parsing_progress.txt', 'w') as f:\n",
    "    f.write(str(article_id) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165e41cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
