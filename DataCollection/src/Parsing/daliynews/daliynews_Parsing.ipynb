{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53f723e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('csv_progress.txt', 'w') as f:\n",
    "    f.write('841024')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f00dc85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index TXT Processing ID: 841025\n",
      "Index TXT Processing ID: 841026\n",
      "Index TXT Processing ID: 841068\n",
      "Index TXT Processing ID: 841079\n",
      "Index TXT Processing ID: 841082\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import chardet\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Detect input file\n",
    "def htmlInput(file_path):\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        encoding_result = chardet.detect(file.read())\n",
    "    with open(file_path, \"r\", encoding=encoding_result[\"encoding\"]) as file:\n",
    "        html_content = file.read()\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "    return soup\n",
    "\n",
    "#Extract title\n",
    "def extract_title(soup):\n",
    "    title = soup.title.string.strip() if soup.title else None\n",
    "    return title\n",
    "\n",
    "#Extract body\n",
    "def extract_body(soup):\n",
    "    article_divs = soup.find_all('div', class_='elementor-widget-container')\n",
    "    articles = []\n",
    "    if article_divs:\n",
    "        for inside_div in article_divs:\n",
    "            articleses = inside_div.find_all('p')\n",
    "            for article in articleses:\n",
    "                articles.append(article.get_text(strip=True))\n",
    "    \n",
    "    articles = [s.replace('\\xa0', ' ') for s in articles]\n",
    "    articles = [item for item in articles if item != '']\n",
    "    return articles\n",
    "\n",
    "#Extract tags\n",
    "def extract_tags(soup):\n",
    "    span_tag = soup.find('span', class_='elementor-post-info__terms-list')\n",
    "    a_tag = span_tag.find('a')\n",
    "    tag_content = a_tag.get_text(strip=True)\n",
    "    return tag_content\n",
    "\n",
    "#Extract date\n",
    "def extract_pubdate(soup):\n",
    "    month_list = {\n",
    "        'มกราคม': '01', \n",
    "        'กุมภาพันธ์': '02', \n",
    "        'มีนาคม': '03', \n",
    "        'เมษายน': '04', \n",
    "        'พฤษภาคม': '05', \n",
    "        'มิถุนายน': '06', \n",
    "        'กรกฎาคม': '07', \n",
    "        'สิงหาคม': '08', \n",
    "        'กันยายน': '09', \n",
    "        'ตุลาคม': '10', \n",
    "        'พฤศจิกายน': '11', \n",
    "        'ธันวาคม': '12'\n",
    "    }\n",
    "    \n",
    "    date_div = soup.find('span', class_='elementor-icon-list-text elementor-post-info__item elementor-post-info__item--type-date')\n",
    "    \n",
    "    if date_div is not None:\n",
    "        date_time_string = date_div.get_text(strip=True)\n",
    "        split_date = date_time_string.split()\n",
    "        \n",
    "        if len(split_date) >= 3:\n",
    "            day, month, year = split_date\n",
    "            numMonth = month_list.get(month)\n",
    "            if year.isdigit():\n",
    "                year = str(int(year) - 543)\n",
    "            datestamps = \"-\".join([year, numMonth, day])\n",
    "            return datestamps\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "#Extract title\n",
    "def extract_intro(soup):\n",
    "    intro_div = soup.find(\"div\", class_=\"css-1wn93q2 evs3ejl67\")\n",
    "    intro = \"\"\n",
    "    if intro_div:\n",
    "        intro_paragraph = intro_div.find('p')\n",
    "        if intro_paragraph:\n",
    "            intro_strong = intro_paragraph.find('strong')\n",
    "            if intro_strong:\n",
    "                intro = intro_strong.get_text(strip=True)\n",
    "    else:\n",
    "        intro = None\n",
    "    return intro\n",
    "def extract_urlPic(soup):\n",
    "    url = None\n",
    "    return url\n",
    "\n",
    "#start using \"csv_progress\" (current progress of parsing)\n",
    "if os.path.exists('csv_progress.txt'):\n",
    "    with open('csv_progress.txt','r') as f:\n",
    "        progress_start = int(f.readline().strip())\n",
    "        start_id = progress_start - 1\n",
    "else: \n",
    "    start_id = 1 \n",
    "    \n",
    "article_id = start_id\n",
    "\n",
    "\n",
    "process = '/Users/macintoshhd/Documents/sp2023/DataSet/daliynews/progress.txt'\n",
    "\n",
    "#start using \"progress\" (last progress of crwaling)\n",
    "if os.path.exists(process):\n",
    "    with open(process,'r') as f:\n",
    "        progress_end = int(f.readline().strip())\n",
    "        end_id = progress_end + 1\n",
    "\n",
    "for article_id in range(start_id, end_id+1):\n",
    "    file_path = \"/Users/macintoshhd/Documents/sp2023/DataSet/daliynews/article/\" + str(article_id) + \"/index.txt\"\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        try:\n",
    "        \n",
    "            soup = htmlInput(file_path)\n",
    "            title = extract_title(soup)\n",
    "            intro = extract_intro(soup)\n",
    "            articles = extract_body(soup)\n",
    "            pubdate = extract_pubdate(soup)\n",
    "            tag_content = extract_tags(soup)\n",
    "            url = extract_urlPic(soup)\n",
    "\n",
    "            data_dict = {'Title': title, 'Intro': intro, 'Article': articles, 'DateTime': pubdate, 'Tags': tag_content, 'url_picture': url}\n",
    "\n",
    "            with open(\"/Users/macintoshhd/Documents/sp2023/DataSet/daliynews/article/\" + str(article_id) + \"/parsed.txt\", 'w', encoding=\"utf-8\") as f:\n",
    "                for key, value in data_dict.items():\n",
    "                    if value is not None:\n",
    "                        if key == 'Tags' and isinstance(value, list):\n",
    "                            f.write(f\"[::{key}::]\\n\")\n",
    "                            for tags in value:\n",
    "                                f.write(f\"{tags}\\n\")\n",
    "\n",
    "                        elif key == 'Article' and isinstance(value, list):\n",
    "                            f.write(f\"[::{key}::]\\n\")\n",
    "                            for bodys in value:\n",
    "                                if bodys == 'SPONSORED':\n",
    "                                    continue\n",
    "                                else:\n",
    "                                    f.write(f\"{bodys}\\n\")\n",
    "                                    f.write(\"\\n\")\n",
    "                        else:\n",
    "                            f.write(f\"[::{key}::]\\n{value}\\n\")\n",
    "\n",
    "\n",
    "            with open('parsing_progress.txt', 'w') as f:\n",
    "                f.write(f'{article_id}')\n",
    "\n",
    "            with open('parsing_number.csv', 'a', newline='') as f:\n",
    "                writer = csv.writer(f)\n",
    "                validation = 'Valid'\n",
    "                writer.writerow([article_id, validation])\n",
    "\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing article {article_id}: {e}\")\n",
    "            with open('parsing_number.csv', 'a', newline='') as f:\n",
    "                writer = csv.writer(f)\n",
    "                validation = 'Error'\n",
    "                writer.writerow([article_id, validation])\n",
    "                continue\n",
    "\n",
    "\n",
    "# Write the last processed article_id to 'csv_progress.txt' after loop ends\n",
    "with open('parsing_progress.txt', 'w') as f:\n",
    "    f.write(str(article_id) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb039cc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
