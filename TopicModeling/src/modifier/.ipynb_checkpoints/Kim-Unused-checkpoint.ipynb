{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6fa7ea05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_excel('C:/Users/uSeR/Documents/VScode/sp2023-stock/TopicModeling/result/RawOutput/TopicWithLabel.xlsx')\n",
    "\n",
    "# List of industries\n",
    "industries = ['AGRO', 'CONSUMP', 'FINCIAL', 'INDUS', 'PROPCON', 'RESOURC', 'SERVICE', 'TECH']\n",
    "\n",
    "# Dictionary to hold topics for each industry\n",
    "industry_topics = {industry: [] for industry in industries}\n",
    "\n",
    "# Loop through each industry and extract topics\n",
    "for industry in industries:\n",
    "    industry_rows = df[df['Industry'].str.contains(industry, na=False)]\n",
    "    topics = industry_rows['Topic'].tolist()\n",
    "    industry_topics[industry] = topics\n",
    "\n",
    "# industry_topics now contains the list of topics for each industry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4f79f8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Topic_0',\n",
       " 'Topic_1',\n",
       " 'Topic_2',\n",
       " 'Topic_3',\n",
       " 'Topic_4',\n",
       " 'Topic_5',\n",
       " 'Topic_6',\n",
       " 'Topic_7',\n",
       " 'Topic_8',\n",
       " 'Topic_9',\n",
       " 'Topic_10',\n",
       " 'Topic_11',\n",
       " 'Topic_12',\n",
       " 'Topic_13',\n",
       " 'Topic_14',\n",
       " 'Topic_15',\n",
       " 'Topic_16',\n",
       " 'Topic_17',\n",
       " 'Topic_18',\n",
       " 'Topic_19',\n",
       " 'Topic_20',\n",
       " 'Topic_21',\n",
       " 'Topic_22',\n",
       " 'Topic_23',\n",
       " 'Topic_24',\n",
       " 'Topic_25',\n",
       " 'Topic_26',\n",
       " 'Topic_27',\n",
       " 'Topic_28',\n",
       " 'Topic_29',\n",
       " 'Topic_30',\n",
       " 'Topic_31',\n",
       " 'Topic_32',\n",
       " 'Topic_33',\n",
       " 'Topic_34',\n",
       " 'Topic_35',\n",
       " 'Topic_36',\n",
       " 'Topic_37',\n",
       " 'Topic_38',\n",
       " 'Topic_39',\n",
       " 'Topic_40',\n",
       " 'Topic_41',\n",
       " 'Topic_42',\n",
       " 'Topic_43',\n",
       " 'Topic_44',\n",
       " 'Topic_45',\n",
       " 'Topic_46',\n",
       " 'Topic_47',\n",
       " 'Topic_48',\n",
       " 'Topic_49',\n",
       " 'Topic_50',\n",
       " 'Topic_51',\n",
       " 'Topic_52',\n",
       " 'Topic_53',\n",
       " 'Topic_54',\n",
       " 'Topic_55',\n",
       " 'Topic_56',\n",
       " 'Topic_57',\n",
       " 'Topic_58',\n",
       " 'Topic_59',\n",
       " 'Topic_60',\n",
       " 'Topic_61',\n",
       " 'Topic_62',\n",
       " 'Topic_63',\n",
       " 'Topic_64',\n",
       " 'Topic_65',\n",
       " 'Topic_66',\n",
       " 'Topic_67',\n",
       " 'Topic_68',\n",
       " 'Topic_69',\n",
       " 'Topic_70',\n",
       " 'Topic_71',\n",
       " 'Topic_72',\n",
       " 'Topic_73',\n",
       " 'Topic_74',\n",
       " 'Topic_75',\n",
       " 'Topic_76',\n",
       " 'Topic_77',\n",
       " 'Topic_78',\n",
       " 'Topic_79',\n",
       " 'Topic_80',\n",
       " 'Topic_81',\n",
       " 'Topic_82',\n",
       " 'Topic_83',\n",
       " 'Topic_84',\n",
       " 'Topic_85',\n",
       " 'Topic_86',\n",
       " 'Topic_87',\n",
       " 'Topic_88',\n",
       " 'Topic_89',\n",
       " 'Topic_90',\n",
       " 'Topic_91',\n",
       " 'Topic_92',\n",
       " 'Topic_93',\n",
       " 'Topic_94',\n",
       " 'Topic_95',\n",
       " 'Topic_96',\n",
       " 'Topic_97',\n",
       " 'Topic_98',\n",
       " 'Topic_99',\n",
       " 'Topic_100',\n",
       " 'Topic_101',\n",
       " 'Topic_102',\n",
       " 'Topic_103',\n",
       " 'Topic_104',\n",
       " 'Topic_105',\n",
       " 'Topic_106',\n",
       " 'Topic_107',\n",
       " 'Topic_108',\n",
       " 'Topic_109',\n",
       " 'Topic_110',\n",
       " 'Topic_111',\n",
       " 'Topic_112',\n",
       " 'Topic_113',\n",
       " 'Topic_114',\n",
       " 'Topic_115',\n",
       " 'Topic_116',\n",
       " 'Topic_117',\n",
       " 'Topic_118',\n",
       " 'Topic_119',\n",
       " 'Topic_120',\n",
       " 'Topic_121',\n",
       " 'Topic_122',\n",
       " 'Topic_123',\n",
       " 'Topic_124',\n",
       " 'Topic_125',\n",
       " 'Topic_126',\n",
       " 'Topic_127',\n",
       " 'Topic_128',\n",
       " 'Topic_129',\n",
       " 'Topic_130',\n",
       " 'Topic_131',\n",
       " 'Topic_132',\n",
       " 'Topic_133',\n",
       " 'Topic_134',\n",
       " 'Topic_135',\n",
       " 'Topic_136',\n",
       " 'Topic_137',\n",
       " 'Topic_138',\n",
       " 'Topic_139',\n",
       " 'Topic_140',\n",
       " 'Topic_141',\n",
       " 'Topic_142',\n",
       " 'Topic_143',\n",
       " 'Topic_144',\n",
       " 'Topic_145',\n",
       " 'Topic_146',\n",
       " 'Topic_147',\n",
       " 'Topic_148',\n",
       " 'Topic_149',\n",
       " 'Topic_150',\n",
       " 'Topic_151',\n",
       " 'Topic_152',\n",
       " 'Topic_153',\n",
       " 'Topic_154',\n",
       " 'Topic_155',\n",
       " 'Topic_156',\n",
       " 'Topic_157',\n",
       " 'Topic_158',\n",
       " 'Topic_159',\n",
       " 'Topic_160',\n",
       " 'Topic_161',\n",
       " 'Topic_162',\n",
       " 'Topic_163',\n",
       " 'Topic_164',\n",
       " 'Topic_165',\n",
       " 'Topic_166',\n",
       " 'Topic_167',\n",
       " 'Topic_168',\n",
       " 'Topic_169',\n",
       " 'Topic_170',\n",
       " 'Topic_171',\n",
       " 'Topic_172',\n",
       " 'Topic_173',\n",
       " 'Topic_174',\n",
       " 'Topic_175',\n",
       " 'Topic_176',\n",
       " 'Topic_177',\n",
       " 'Topic_178',\n",
       " 'Topic_179',\n",
       " 'Topic_180',\n",
       " 'Topic_181',\n",
       " 'Topic_182',\n",
       " 'Topic_183',\n",
       " 'Topic_184',\n",
       " 'Topic_185',\n",
       " 'Topic_186',\n",
       " 'Topic_187',\n",
       " 'Topic_188',\n",
       " 'Topic_189',\n",
       " 'Topic_190',\n",
       " 'Topic_191',\n",
       " 'Topic_192',\n",
       " 'Topic_193',\n",
       " 'Topic_194',\n",
       " 'Topic_195',\n",
       " 'Topic_196',\n",
       " 'Topic_197',\n",
       " 'Topic_198',\n",
       " 'Topic_199']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0a6855f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429867.0\n",
      "Topic_190    0.331024\n",
      "Topic_115    0.274141\n",
      "Topic_21     0.078868\n",
      "Topic_34     0.050422\n",
      "Topic_7      0.049530\n",
      "Topic_76     0.037494\n",
      "Topic_163    0.037472\n",
      "Topic_104    0.028665\n",
      "Topic_81     0.028634\n",
      "Topic_90     0.026647\n",
      "Name: 0, dtype: float64\n",
      "429872.0\n",
      "Topic_199    0.226669\n",
      "Topic_136    0.182128\n",
      "Topic_147    0.115744\n",
      "Topic_175    0.112938\n",
      "Topic_82     0.088691\n",
      "Topic_76     0.073755\n",
      "Topic_89     0.048278\n",
      "Topic_177    0.041859\n",
      "Topic_141    0.030515\n",
      "Topic_193    0.024991\n",
      "Name: 1, dtype: float64\n",
      "429873.0\n",
      "Topic_49     0.197400\n",
      "Topic_21     0.106862\n",
      "Topic_179    0.083030\n",
      "Topic_133    0.081942\n",
      "Topic_192    0.078825\n",
      "Topic_118    0.070003\n",
      "Topic_189    0.057775\n",
      "Topic_138    0.052025\n",
      "Topic_6      0.050266\n",
      "Topic_176    0.048848\n",
      "Name: 2, dtype: float64\n",
      "429882.0\n",
      "Topic_61     0.143945\n",
      "Topic_55     0.126567\n",
      "Topic_92     0.096318\n",
      "Topic_135    0.094584\n",
      "Topic_134    0.073842\n",
      "Topic_174    0.061963\n",
      "Topic_15     0.061356\n",
      "Topic_110    0.053524\n",
      "Topic_192    0.053046\n",
      "Topic_108    0.048009\n",
      "Name: 3, dtype: float64\n",
      "429884.0\n",
      "Topic_92     0.243199\n",
      "Topic_147    0.165860\n",
      "Topic_55     0.143713\n",
      "Topic_194    0.114447\n",
      "Topic_136    0.098293\n",
      "Topic_116    0.082886\n",
      "Topic_53     0.056529\n",
      "Topic_61     0.053368\n",
      "Topic_25     0.021374\n",
      "Topic_0      0.000106\n",
      "Name: 4, dtype: float64\n",
      "429886.0\n",
      "Topic_92     0.672231\n",
      "Topic_138    0.073003\n",
      "Topic_24     0.065297\n",
      "Topic_20     0.055893\n",
      "Topic_7      0.046456\n",
      "Topic_61     0.035437\n",
      "Topic_12     0.035045\n",
      "Topic_0      0.000086\n",
      "Topic_1      0.000086\n",
      "Topic_2      0.000086\n",
      "Name: 5, dtype: float64\n",
      "429888.0\n",
      "Topic_57     0.373154\n",
      "Topic_72     0.291439\n",
      "Topic_194    0.106994\n",
      "Topic_190    0.072003\n",
      "Topic_62     0.037024\n",
      "Topic_21     0.029934\n",
      "Topic_146    0.027088\n",
      "Topic_103    0.021612\n",
      "Topic_60     0.019973\n",
      "Topic_183    0.000109\n",
      "Name: 6, dtype: float64\n",
      "429892.0\n",
      "Topic_151    0.384758\n",
      "Topic_165    0.166780\n",
      "Topic_21     0.142132\n",
      "Topic_143    0.084767\n",
      "Topic_126    0.055235\n",
      "Topic_10     0.054977\n",
      "Topic_174    0.025181\n",
      "Topic_5      0.023039\n",
      "Topic_194    0.022347\n",
      "Topic_46     0.020985\n",
      "Name: 7, dtype: float64\n",
      "13098182.0\n",
      "Topic_123    4.253279\n",
      "Topic_26     2.186337\n",
      "Topic_136    2.043497\n",
      "Topic_89     1.958095\n",
      "Topic_23     1.827294\n",
      "Topic_42     1.593083\n",
      "Topic_50     1.561844\n",
      "Topic_197    1.548686\n",
      "Topic_100    1.496755\n",
      "Topic_17     1.445520\n",
      "Name: 8, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your Excel file\n",
    "df = pd.read_excel('C:/Users/uSeR/Documents/VScode/sp2023-stock/TopicModeling/result/SampleVersion/TopicWithValueSample.xlsx')\n",
    "\n",
    "topic_columns = [col for col in df.columns if col.startswith('Topic_')]\n",
    "\n",
    "for col in topic_columns:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Iterate over the DataFrame rows\n",
    "for index, row in df.iterrows():\n",
    "    print(row[0])\n",
    "    # Get the topic columns for the current row, drop missing values, and find the indices of the top 3 values\n",
    "    top_values = row[topic_columns].dropna().nlargest(10)\n",
    "    top_indices = top_values.index\n",
    "    print(top_values)\n",
    "    # Set all other values to 0\n",
    "    for col in topic_columns:\n",
    "        if col not in top_indices:\n",
    "            df.at[index, col] = 0\n",
    "            \n",
    "#df.to_excel('C:/Users/uSeR/Documents/VScode/sp2023-stock/TopicModeling/result/TopValueOutput/TopicWithTop10Value.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ffe69f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article_ID</th>\n",
       "      <th>Topic_0</th>\n",
       "      <th>Topic_1</th>\n",
       "      <th>Topic_2</th>\n",
       "      <th>Topic_3</th>\n",
       "      <th>Topic_4</th>\n",
       "      <th>Topic_5</th>\n",
       "      <th>Topic_6</th>\n",
       "      <th>Topic_7</th>\n",
       "      <th>Topic_8</th>\n",
       "      <th>...</th>\n",
       "      <th>Topic_190</th>\n",
       "      <th>Topic_191</th>\n",
       "      <th>Topic_192</th>\n",
       "      <th>Topic_193</th>\n",
       "      <th>Topic_194</th>\n",
       "      <th>Topic_195</th>\n",
       "      <th>Topic_196</th>\n",
       "      <th>Topic_197</th>\n",
       "      <th>Topic_198</th>\n",
       "      <th>Topic_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>429867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.331024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>429872</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.226669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>429873</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>429882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>429884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>429886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>429888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.106994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>429892</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13098182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Article_ID  Topic_0  Topic_1  Topic_2  Topic_3  Topic_4  Topic_5  Topic_6  \\\n",
       "0      429867      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1      429872      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2      429873      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3      429882      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4      429884      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "5      429886      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "6      429888      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "7      429892      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "8    13098182      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   Topic_7  Topic_8  ...  Topic_190  Topic_191  Topic_192  Topic_193  \\\n",
       "0      0.0      0.0  ...   0.331024        0.0        0.0        0.0   \n",
       "1      0.0      0.0  ...   0.000000        0.0        0.0        0.0   \n",
       "2      0.0      0.0  ...   0.000000        0.0        0.0        0.0   \n",
       "3      0.0      0.0  ...   0.000000        0.0        0.0        0.0   \n",
       "4      0.0      0.0  ...   0.000000        0.0        0.0        0.0   \n",
       "5      0.0      0.0  ...   0.000000        0.0        0.0        0.0   \n",
       "6      0.0      0.0  ...   0.000000        0.0        0.0        0.0   \n",
       "7      0.0      0.0  ...   0.000000        0.0        0.0        0.0   \n",
       "8      0.0      0.0  ...   0.000000        0.0        0.0        0.0   \n",
       "\n",
       "   Topic_194  Topic_195  Topic_196  Topic_197  Topic_198  Topic_199  \n",
       "0   0.000000        0.0        0.0        0.0        0.0   0.000000  \n",
       "1   0.000000        0.0        0.0        0.0        0.0   0.226669  \n",
       "2   0.000000        0.0        0.0        0.0        0.0   0.000000  \n",
       "3   0.000000        0.0        0.0        0.0        0.0   0.000000  \n",
       "4   0.000000        0.0        0.0        0.0        0.0   0.000000  \n",
       "5   0.000000        0.0        0.0        0.0        0.0   0.000000  \n",
       "6   0.106994        0.0        0.0        0.0        0.0   0.000000  \n",
       "7   0.000000        0.0        0.0        0.0        0.0   0.000000  \n",
       "8   0.000000        0.0        0.0        0.0        0.0   0.000000  \n",
       "\n",
       "[9 rows x 201 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c4f96c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Load your data\n",
    "# df = pd.read_excel('C:/Users/uSeR/Documents/VScode/sp2023-stock/TopicModeling/result/Modified_TopicWithValueSample.xlsx')\n",
    "\n",
    "\n",
    "# id_vars = ['Article_ID', 'Date']  # These are the columns that we don't want to melt\n",
    "# value_vars = [col for col in df.columns if col.startswith('Topic_')]  # These are the topic columns\n",
    "\n",
    "# # Melt the DataFrame\n",
    "# df_long = df.melt(id_vars=id_vars, value_vars=value_vars, var_name='Topic', value_name='Value')\n",
    "\n",
    "# # Now, go through each industry and its topics\n",
    "# for industry, topics in industry_topics.items():\n",
    "#     # Filter the dataframe for the current industry's topics\n",
    "#     industry_df = df_long[df_long['Topic'].isin(topics)]\n",
    "    \n",
    "#     # Now, if needed, pivot back to wide format or group by Article_ID and Date\n",
    "#     # Group by Date and sum the values\n",
    "#     industry_df_grouped = industry_df.groupby('Date').sum().reset_index()\n",
    "    \n",
    "#     # Save the grouped dataframe to a new CSV file named after the industry\n",
    "#     industry_df_grouped.to_csv(f'C:/Users/uSeR/Documents/VScode/sp2023-stock/TopicModeling/result/Output/{industry}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226a3d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# # Load the Excel file\n",
    "# df = pd.read_excel('C:/Users/uSeR/Documents/VScode/sp2023-stock/TopicModeling/result/Modified_TopicWithValueSample.xlsx')\n",
    "\n",
    "# # Iterate over each industry\n",
    "# for industry, topics in industry_topics.items():\n",
    "#     # Select only the columns for the specified topics and the 'Date' column\n",
    "#     selected_columns = ['Date'] + [f'Topic_{t.split(\" \")[1]}' for t in topics if t]\n",
    "#     industry_df = df[selected_columns]\n",
    "\n",
    "#     # Save the DataFrame to a CSV file\n",
    "#     industry_df.to_csv(f'C:/Users/uSeR/Documents/VScode/sp2023-stock/TopicModeling/result/Output/Coparer/{industry}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e79ce7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Load the Excel file\n",
    "# df = pd.read_excel('C:/Users/uSeR/Documents/VScode/sp2023-stock/TopicModeling/result/Modified_TopicWithValue.xlsx')\n",
    "\n",
    "\n",
    "# # Iterate over each industry\n",
    "# for industry, topics in industry_topics.items():\n",
    "#     # Convert topic numbers in the list to column names\n",
    "#     topic_columns = [f'Topic_{t.split()[1]}' for t in topics]\n",
    "\n",
    "#     # Select only the columns for the specified topics and the 'Date' column\n",
    "#     selected_columns = ['Date'] + topic_columns\n",
    "#     industry_df = df[selected_columns]\n",
    "\n",
    "#     # Group by 'Date' and sum the values\n",
    "#     industry_grouped = industry_df.groupby('Date').sum().reset_index()\n",
    "\n",
    "#     # Save the grouped DataFrame to a CSV file\n",
    "#     industry_grouped.to_csv(f'C:/Users/uSeR/Documents/VScode/sp2023-stock/TopicModeling/result/Output/{industry}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02298704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_excel('C:/Users/uSeR/Documents/VScode/sp2023-stock/TopicModeling/result/TopValueOutput/TopicWithTop10Value.xlsx')\n",
    "\n",
    "\n",
    "# Convert 'Date' column to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Filter the DataFrame for the date range\n",
    "start_date = '2018-01-23'\n",
    "end_date = '2023-08-18'\n",
    "df = df[(df['Date'] >= start_date) & (df['Date'] <= end_date)]\n",
    "\n",
    "# Iterate over each industry\n",
    "for industry, topics in industry_topics.items():\n",
    "    # Convert topic numbers in the list to column names\n",
    "    topic_columns = [f'Topic_{t.split()[1]}' for t in topics]\n",
    "\n",
    "    # Select only the columns for the specified topics and the 'Date' column\n",
    "    selected_columns = ['Date'] + topic_columns\n",
    "    industry_df = df[selected_columns]\n",
    "\n",
    "    # Group by 'Date' and sum the values\n",
    "    industry_grouped = industry_df.groupby('Date').sum().reset_index()\n",
    "\n",
    "    # Create a complete date range\n",
    "    all_dates = pd.date_range(start=start_date, end=end_date)\n",
    "    \n",
    "    # Reindex to include all dates, filling missing ones with 0\n",
    "    industry_grouped.set_index('Date', inplace=True)\n",
    "    industry_grouped = industry_grouped.reindex(all_dates, fill_value=0).reset_index()\n",
    "\n",
    "    # Rename 'index' column back to 'Date'\n",
    "    industry_grouped.rename(columns={'index': 'Date'}, inplace=True)\n",
    "\n",
    "    # Save to CSV\n",
    "    industry_grouped.to_csv(f'C:/Users/uSeR/Documents/VScode/sp2023-stock/TopicModeling/result/Output/{industry}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab90ea15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
