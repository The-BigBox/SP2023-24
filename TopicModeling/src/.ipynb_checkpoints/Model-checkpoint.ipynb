{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe1277a-875d-4e88-8453-efc07bff98b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.corpora import Dictionary, MmCorpus\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "%env JOBLIB_TEMP_FOLDER= 'E:/sp2023stock/TopicModeling/tmp'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0fb6aa-f3c7-4d67-988e-d64018c221a2",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afe5ee8-64ca-440b-83bb-1e73377e7aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 100\n",
    "\n",
    "main = os.getcwd()\n",
    "#in\n",
    "#model_path_asset = main + \"/../model/ModelingAssets/CorpusDict\"\n",
    "model_path_asset_1mill = main + \"/../model/ModelingAssets/1mill/CorpusDict\"\n",
    "\n",
    "#out\n",
    "model_path_state = main + \"/../model/ModelingState\"\n",
    "output_result = main + \"/../result/modelOutput\"\n",
    "\n",
    "\n",
    "model_path_asset_spenum = model_path_asset_1mill+str(num)\n",
    "model_path_asset_spenum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9f4dfc-a49b-4bae-ad4e-2fe4eb397568",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Dataset loading  dictionary - corpus - json\")\n",
    "# Load the dictionary and corpus\n",
    "dictionary = Dictionary.load(f'{model_path_asset_spenum}/dictionary.gensim')\n",
    "corpus = MmCorpus(f'{model_path_asset_spenum}/corpus.mm')\n",
    "# json_file_path = f'{model_path_asset_spenum}/dataset_{num}.json'\n",
    "\n",
    "# with open(json_file_path, 'r', encoding='utf-8') as json_file:\n",
    "#     dataset = json.load(json_file)\n",
    "    \n",
    "print(f\"Dataset loaded - dictionary {len(dictionary)} - corpus {len(corpus)} - json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5a3df2-88b0-4259-871c-5a866270603b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 400\n",
    "total_iterations = 2000\n",
    "save_interval = 100\n",
    "\n",
    "# Initialize LDA model\n",
    "\n",
    "print(f\"Running the model using corpus: {len(corpus)}, iterations: {total_iterations}, number of topic: {num_topics}\")\n",
    "\n",
    "lda = gensim.models.ldamulticore.LdaMulticore(\n",
    "    corpus=corpus,\n",
    "    id2word=dictionary,\n",
    "    num_topics=num_topics,\n",
    "    iterations= total_iterations\n",
    "    \n",
    ")\n",
    "\n",
    "print(\"Finishing\")\n",
    "print(\"\\n\")\n",
    "print(\"Saving\")\n",
    "\n",
    "filename = os.path.join(model_path_state, f'lda_model_n{num_topics}_iterations{total_iterations}_size100.gensim')\n",
    "lda.save(filename)\n",
    "print(f\"Saved model at pass number {total_iterations} to {filename}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16412849-d236-43dc-a592-b9f4da4230cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(model_path_state, f'lda_model_n{num_topics}_iterations{total_iterations}_size100.gensim')\n",
    "lda.save(filename)\n",
    "print(f\"Saved model at pass number {total_iterations} to {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d662ba8-d99a-485f-afb3-267792487834",
   "metadata": {},
   "source": [
    "#### Loading (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e49108e-e2bb-4821-a717-37a1fe901694",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(model_path_state, f'lda_model_n400_iterations2000_size100.gensim')\n",
    "lda = LdaModel.load(filename)\n",
    "print(f\"Load model Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5084910d-f4fa-4210-8e6e-7281552c34e9",
   "metadata": {},
   "source": [
    "#### Inferanceing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca209da-81a6-464d-af9c-6713fa1850a0",
   "metadata": {},
   "source": [
    "###### Print Distribution of each articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c962cf-5898-4af0-be5d-c2dfc17fd949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get topic distribution for each document\n",
    "doc_topic_dists = [lda.get_document_topics(item, minimum_probability=0) for item in corpus]\n",
    "\n",
    "# Convert the topic distributions into a structured format\n",
    "doc_topics = []\n",
    "for doc_dist in doc_topic_dists:\n",
    "    doc_topics.append([prob for _, prob in doc_dist])\n",
    "\n",
    "# Create a DataFrame\n",
    "doc_topics_df = pd.DataFrame(doc_topics, columns=[f\"Topic_{i}\" for i in range(num_topics)])\n",
    "\n",
    "# # If you have a list of article IDs, you can insert them too\n",
    "# doc_topics_df.insert(0, 'Article_ID', processed_article_ids)\n",
    "doc_topic_out = os.path.join(output_result, 'document_topics.csv') \n",
    "doc_topics_df.to_csv(doc_topic_out, index=False)\n",
    "\n",
    "print(f\"Topic distribution for each article is completely saved at {doc_topic_out}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2c9592-f66e-4eb5-ba88-746dde36d490",
   "metadata": {},
   "source": [
    "###### Print Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad2200f-2acb-48e0-89e9-e26ecf70bf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store the topics data\n",
    "topics_data = []\n",
    "num_topics = 400\n",
    "num_showwords = 100\n",
    "print(f\"Total of words in each topic are{num_showwords}\") \n",
    "\n",
    "for i in range(num_topics):\n",
    "    words = lda.show_topic(i, num_showwords)\n",
    "    topic_words = [word[0] for word in words]\n",
    "    topics_data.append(topic_words)\n",
    "\n",
    "# Create a DataFrame from the topics data\n",
    "df_topics = pd.DataFrame(topics_data, index=[f\"Topic {i}\" for i in range(num_topics)], columns=[f\"Word {i+1}\" for i in range(num_showwords)])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_file_path = os.path.join(output_result, 'word_topics.csv')\n",
    "df_topics.to_csv(csv_file_path, index=True)\n",
    "\n",
    "print(f\"Words for each topic is completely saved at {csv_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
